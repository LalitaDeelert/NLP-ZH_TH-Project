{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with OpenSubtitles dataset. We explore the following aspects of the dataset:\n",
    "0. Drop all duplicates.\n",
    "1. How many characters in each line / average / total for dataset (`th` and `zh`)?\n",
    "2. How many words in each line / average / total for dataset (`th` tokenized by `pythainlp.tokenize`; check your pythainlp version)?\n",
    "3. How many words in each line / average / total for dataset (try `zh` tokenizers [jieba](https://github.com/fxsjy/jieba), [pkuseg](https://github.com/explosion/spacy-pkuseg/blob/master/readme/readme_english.md), or any other ones you find interesting)?\n",
    "4. zh-to-th word ratio in each line / average for dataset; for example, `(我吃飯, ฉันกินข้าว)` has 3 `zh` words and 3 `th` words so the ratio is $3/3=1$)\n",
    "5. Find similarity score for each sentence pair and average for dataset using [multilingual universal sentence encoder](https://tfhub.dev/google/universal-sentence-encoder-multilingual/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #read full dataset\n",
    "# with open(\"../data/OpenSubtitles/OpenSubtitles.th-zh_cn.th\",\"r\",encoding='utf-8') as f:\n",
    "#     th_lines = f.readlines()\n",
    "#     th_lines = [i[:-1] for i in th_lines]\n",
    "# with open(\"../data/OpenSubtitles/OpenSubtitles.th-zh_cn.zh_cn\",\"r\",encoding='utf-8') as f:\n",
    "#     zh_lines = f.readlines()\n",
    "#     zh_lines = [i[:-1] for i in zh_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read sample dataset\n",
    "with open(\"../data/OpenSubtitles/OpenSubtitles_sample.th\", \"r\", encoding='utf-8') as f:\n",
    "    th_lines = f.readlines()\n",
    "    th_lines = [i[:-1] for i in th_lines]\n",
    "with open(\"../data/OpenSubtitles/OpenSubtitles_sample.zh_cn\", \"r\", encoding='utf-8') as f:\n",
    "    zh_lines = f.readlines()\n",
    "    zh_lines = [i[:-1] for i in zh_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(th_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['คุณจำตอนพิธีล้างบาปของคุณได้ เป็นไปได้ยังไง?',\n",
       " 'เป็นไปไม่ได้รึไง? แต่มันจริงนะ',\n",
       " 'คุณได้ยินผู้ใหญ่เขาคุยกันรึเปล่า?',\n",
       " 'ฉันรู้สึกได้ถึงแสงอาทิตย์ลอดผ่านกระจกเข้ามา',\n",
       " 'ฉันยังจำเสียงหัวใจเต้นของพ่อได้',\n",
       " 'ไม่ใช่ฉันที่จำได้ แต่เป็นความทรงจำของฉันต่างหาก',\n",
       " 'แต่คุณไม่ใช่ คาธอลิกแล้วนี่?',\n",
       " 'เขาปล่อยให้คนอื่นผ่านไป',\n",
       " 'ทำไมอยู่ดีๆถึงพูดเรื่องพิธีล้างบาปขึ้นมาล่ะ?',\n",
       " 'ฉันนึกถึงมันบ่อยๆ บางทีฉันก็จำได้']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zh_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['记得自己的洗礼仪式 这可能吗?',\n",
       " '不可能?',\n",
       " '可那是事实啊 是听大人们说的吧?',\n",
       " '我能感受到透过玻璃的阳光',\n",
       " '我还记得爸爸的心跳声呢',\n",
       " '真的不是听来的 是记忆里的',\n",
       " '你也不是信天主教的吧',\n",
       " '改新教也有洗礼这种仪式',\n",
       " '为什么忽然提起洗礼仪式?',\n",
       " '最近想起来的 偶尔会想起']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zh_lines[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [multilingual universal sentence encoder](https://tfhub.dev/google/universal-sentence-encoder-multilingual/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from [thai2nmt](https://github.com/vistec-AI/thai2nmt_preprocess/blob/master/clean_subdataset.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_score(lang1: str, lang2: str, batch_size: int, embed):\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    if len(lang1) % batch_size != 0:\n",
    "        num_of_batch = int(len(lang1)/batch_size)+1\n",
    "    else:\n",
    "        num_of_batch = int(len(lang1)/batch_size)\n",
    "\n",
    "    for i in range(num_of_batch):\n",
    "        start = i*batch_size\n",
    "        end = start+batch_size\n",
    "        if i <= num_of_batch:\n",
    "\n",
    "            lang1_temp = lang1[start:end]\n",
    "            lang2_temp = lang2[start:end]\n",
    "\n",
    "            lang1_embedding = embed(lang1_temp)\n",
    "            lang2_embedding = embed(lang2_temp)\n",
    "            distance_matrix = tf.matmul(\n",
    "                lang1_embedding, lang2_embedding, transpose_b=True).numpy()\n",
    "\n",
    "            for j in range(len(distance_matrix)):\n",
    "                scores.append(distance_matrix[j][j])\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0512 16:14:01.669605 140226635827008 def_function.py:120] 6 out of the last 8 calls to <function recreate_function.<locals>.restored_function_body at 0x7f890416f950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "W0512 16:14:01.699396 140226635827008 def_function.py:120] 7 out of the last 9 calls to <function recreate_function.<locals>.restored_function_body at 0x7f884d38ad08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "zhs = [\n",
    "    '我吃食物',\n",
    "    '她喜歡看電視',\n",
    "    '她為什麼喜歡吃電視',\n",
    "    '我吃食物',\n",
    "    '她喜歡看電視',\n",
    "    '她為什麼喜歡吃電視'\n",
    "]\n",
    "ths = [\n",
    "    'ฉันกินอาหาร',\n",
    "    'เธอชอบดูทีวี',\n",
    "    'ทำไมเธอถึงชอบกินทีวี',\n",
    "    'ฉันไม่ชอบกินอาหาร',\n",
    "    'เธอเกลียดทีวี',\n",
    "    'ทำไมทีวีกินเธอเข้าไป',\n",
    "]\n",
    "\n",
    "emb = hub.load('https://tfhub.dev/google/universal-sentence-encoder-multilingual/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0512 16:04:15.366335 140226635827008 def_function.py:120] 5 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7f884d378268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.88183826, 0.6799599, 0.732453, 0.6549038, 0.57960916, 0.7019044]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similar_score(zhs, ths, 16, emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0512 16:14:12.142370 140226635827008 def_function.py:120] 8 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7f88743516a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "sims = get_similar_score(zh_lines, th_lines, 16, emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zh</th>\n",
       "      <th>th</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>改新教也有洗礼这种仪式</td>\n",
       "      <td>เขาปล่อยให้คนอื่นผ่านไป</td>\n",
       "      <td>0.073779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>真是小气</td>\n",
       "      <td>คุณคิดเอาไว้ก่อนอยู่แล้วจริงๆ</td>\n",
       "      <td>0.086167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>例如</td>\n",
       "      <td>การจ่ายค่าชดเชย</td>\n",
       "      <td>0.094630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>就放在抽屉的深处</td>\n",
       "      <td>ฉันก็เลยเก็บให้พ้นตา</td>\n",
       "      <td>0.148213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>你下来坐</td>\n",
       "      <td>มานั่งตรงนี้สิ หลังผมจะเย็นพอดี</td>\n",
       "      <td>0.154625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2万1000 不知道有没有500的</td>\n",
       "      <td>20000, 1000 ฉันไม่รู้ว่าจะมี 500 วอนรึเปล่า</td>\n",
       "      <td>0.741247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>这个为什么会在厨房里</td>\n",
       "      <td>ทำไมนี่ถึงอยู่ในครัวน่ะ</td>\n",
       "      <td>0.754683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>真的?</td>\n",
       "      <td>จริงเหรอ?</td>\n",
       "      <td>0.793694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>为什么?</td>\n",
       "      <td>ทำไมล่ะ?</td>\n",
       "      <td>0.845884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>什么?</td>\n",
       "      <td>อะไรนะ?</td>\n",
       "      <td>0.932120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   zh                                           th  \\\n",
       "7         改新教也有洗礼这种仪式                      เขาปล่อยให้คนอื่นผ่านไป   \n",
       "22               真是小气                คุณคิดเอาไว้ก่อนอยู่แล้วจริงๆ   \n",
       "84                 例如                              การจ่ายค่าชดเชย   \n",
       "73           就放在抽屉的深处                         ฉันก็เลยเก็บให้พ้นตา   \n",
       "56               你下来坐              มานั่งตรงนี้สิ หลังผมจะเย็นพอดี   \n",
       "..                ...                                          ...   \n",
       "35  2万1000 不知道有没有500的  20000, 1000 ฉันไม่รู้ว่าจะมี 500 วอนรึเปล่า   \n",
       "90         这个为什么会在厨房里                      ทำไมนี่ถึงอยู่ในครัวน่ะ   \n",
       "68                真的?                                    จริงเหรอ?   \n",
       "12               为什么?                                     ทำไมล่ะ?   \n",
       "76                什么?                                      อะไรนะ?   \n",
       "\n",
       "    similarity_score  \n",
       "7           0.073779  \n",
       "22          0.086167  \n",
       "84          0.094630  \n",
       "73          0.148213  \n",
       "56          0.154625  \n",
       "..               ...  \n",
       "35          0.741247  \n",
       "90          0.754683  \n",
       "68          0.793694  \n",
       "12          0.845884  \n",
       "76          0.932120  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#find a good threshold with full dataset\n",
    "sim_df = pd.DataFrame({'zh':zh_lines, 'th': th_lines, 'similarity_score':sims}).sort_values('similarity_score')\n",
    "sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
